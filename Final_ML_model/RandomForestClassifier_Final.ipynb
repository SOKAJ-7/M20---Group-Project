{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c832dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aada5d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rock', 'r&b', 'pop', 'edm', 'latin', 'rap'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import our data\n",
    "songs_df = pd.read_csv('spotify_songs.csv')\n",
    "\n",
    "songs_df['playlist_genre'].unique()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a75459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create subsetted dataframe for our genre\n",
    "genre_df = songs_df[songs_df['playlist_genre'] == 'edm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb3c35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start prepping data for our model\n",
    "#Drop columns not relevant to the model\n",
    "genre_df = genre_df.drop(columns=['key','playlist_genre','playlist_name','track_artist','lyrics','track_album_name','track_name','track_album_id','track_id','track_album_release_date','playlist_id','language','playlist_subgenre','liveness','acousticness','speechiness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b89e822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UP', NaN, 'SWP', 'P']\n",
       "Categories (3, object): ['UP' < 'SWP' < 'P']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bin target variable (popularity) into 3 classes: 'Unpopular', 'Somewhat popular', 'Popular'\n",
    "#bin target variable relative to genre of interest\n",
    "#drop old popularity \n",
    "bins_1 = [0,60,75,100]\n",
    "labels_1 = ['UP','SWP','P']\n",
    "\n",
    "\n",
    "genre_df['popularity_binned'] = pd.cut(genre_df['track_popularity'], bins = bins_1, labels = labels_1)\n",
    "    \n",
    "genre_df = genre_df.drop(columns = ['track_popularity'])\n",
    "\n",
    "genre_df['popularity_binned'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1e60fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UP     1543\n",
      "SWP     182\n",
      "P        23\n",
      "Name: popularity_binned, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#encode categorical variables\n",
    "#Check bin evenness and drop NaN\n",
    "#genre_df = pd.get_dummies(genre_df, columns = ['mode','key','explicit','release_season'])\n",
    "print(genre_df['popularity_binned'].value_counts())\n",
    "\n",
    "genre_df = genre_df.dropna(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af72d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split our data into target and feature variables\n",
    "X = genre_df.drop(columns=['popularity_binned']).values\n",
    "y= genre_df['popularity_binned'].dropna().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b391c757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Test/Train Splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_test, X_train, y_test, y_train = train_test_split(X, y, train_size = 0.50, test_size = 0.50, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccc51adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is two resampling methods, some resampling methods work best \n",
    "# for certain genres so I have included code for both, simply comment out\n",
    "# whatever methods you don't wish to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca51f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix class imbalance by using undersampling\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "#ros = RandomUnderSampler(random_state=1)\n",
    "#X_resampled, y_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5da599b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fix class imbalance by using oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "876c713a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2]), array([763, 763, 763], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#Encode our categorical variables\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_test)\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "encoder.fit(y_resampled)\n",
    "y_train = encoder.transform(y_resampled)\n",
    "\n",
    "print(np.unique(y_train, return_counts = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ecc132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale and Transform our data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_resampled)\n",
    "X_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3f871fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up parameters\n",
    "n_estimators = [5,25,50,100]\n",
    "max_features = ['auto','sqrt']\n",
    "max_depth = [2,3,4,5]\n",
    "criterion = ['gain','entropy']\n",
    "min_samples_split = [2,5,10]\n",
    "min_samples_leaf = [1,2,3]\n",
    "bootstrap = [True,False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "477b2d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Random Forest Classifier model and optimize parameters\n",
    "#rfc = RandomForestClassifier()\n",
    "#parameters = {\n",
    "#    \"n_estimators\": n_estimators,\n",
    "#    \"max_depth\" : max_features,\n",
    "#    \"max_depth\" : max_depth,\n",
    "#   \"min_samples_split\" : min_samples_split,\n",
    "#    \"min_samples_leaf\" : min_samples_leaf,\n",
    "#    \"bootstrap\" : bootstrap\n",
    "#    }\n",
    "#cv = GridSearchCV(rfc,parameters,cv=5)\n",
    "#cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3841cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best model hyperparameters\n",
    "#print(f'The best parameters are {cv.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bb1577c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, min_samples_leaf=3, min_samples_split=5,\n",
       "                       n_estimators=50, random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model with best parameters\n",
    "rfc = RandomForestClassifier(n_estimators = 50, \n",
    "                           max_depth = 5, \n",
    "                           min_samples_split = 5,\n",
    "                           min_samples_leaf =  3,\n",
    "                           bootstrap = True,\n",
    "                           random_state = 0)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3427408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 2, 1,\n",
       "       1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1, 2,\n",
       "       2, 1, 1, 2, 2, 2, 2, 2, 1, 0, 0, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2,\n",
       "       1, 2, 1, 2, 2, 1, 2, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 0, 2, 0, 1, 2,\n",
       "       1, 2, 0, 0, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 1, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 0, 2, 2, 2, 2,\n",
       "       1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       1, 0, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 0, 2, 1, 0, 1, 1, 1, 2,\n",
       "       2, 2, 0, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1,\n",
       "       2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 0, 2, 2, 1, 0, 2, 2, 0,\n",
       "       0, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 0, 2, 2,\n",
       "       2, 2, 2, 1, 2, 1, 1, 0, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2,\n",
       "       0, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2,\n",
       "       1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2,\n",
       "       2, 1, 2, 0, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2,\n",
       "       2, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 0,\n",
       "       1, 1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 0, 0, 2, 2, 2, 2,\n",
       "       1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 0, 2, 2, 1, 2, 1, 2, 1, 2,\n",
       "       1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2,\n",
       "       2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 0, 2, 2, 1, 2, 1, 1, 1,\n",
       "       2, 2, 2, 2, 0, 0, 1, 1, 1, 1, 2, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1, 1,\n",
       "       2, 1, 2, 0, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2,\n",
       "       2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 1,\n",
       "       2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2,\n",
       "       1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 0, 1, 2, 1, 1, 2, 2, 0,\n",
       "       1, 2, 0, 0, 2, 2, 1, 1, 2, 1, 2, 2, 1, 0, 0, 1, 1, 2, 1, 0, 2, 0,\n",
       "       1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 2, 0, 2, 1,\n",
       "       0, 1, 0, 2, 1, 2, 2, 2, 2, 1, 1, 0, 1, 2, 2, 1, 2, 2, 2, 0, 2, 1,\n",
       "       2, 1, 1, 2, 1, 1, 2, 0, 1, 1, 1, 1, 0, 2, 2, 1, 2, 2, 1, 2, 2, 1,\n",
       "       0, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2,\n",
       "       0, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 2, 1, 2, 0, 1, 2, 0, 2, 2, 1, 1, 2, 1, 2, 2, 2, 0, 0, 2, 1,\n",
       "       1, 2, 1, 2, 2, 0, 2, 0, 0, 2, 1, 1, 0, 2, 1, 2, 1, 1, 0, 0, 1, 2,\n",
       "       2, 0, 1, 1, 1, 2, 1, 0, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 0, 1, 2, 0,\n",
       "       1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 0, 2, 2, 1, 1, 2,\n",
       "       2, 1, 1, 0, 1, 1, 0, 1, 2, 0, 1, 2, 2, 1, 1, 1, 2, 1, 1, 0, 2, 2,\n",
       "       2, 2, 2, 1, 2, 1, 2, 0, 2, 2, 1, 2, 2, 1, 1, 2, 0, 2, 1, 2, 2, 2,\n",
       "       2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 0, 2, 2, 2, 1,\n",
       "       2, 2, 1, 1, 1, 0, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0,\n",
       "       2, 2, 1, 2, 2, 2, 0, 1, 2, 1, 2, 1, 2, 1, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions\n",
    "y_pred = rfc.predict(X_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "833db1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating confusion matrices\n",
    "mcm = multilabel_confusion_matrix(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "944cbd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_U</th>\n",
       "      <th>Actual_A</th>\n",
       "      <th>Pred_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual_U</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual_A</th>\n",
       "      <td>13</td>\n",
       "      <td>49</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual_P</th>\n",
       "      <td>72</td>\n",
       "      <td>328</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred_U  Actual_A  Pred_P\n",
       "Actual_U       1         5       2\n",
       "Actual_A      13        49      24\n",
       "Actual_P      72       328     380"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn our confusion matrices into a dataframe\n",
    "cm_df = pd.DataFrame(cm, index = ['Actual_U','Actual_A','Actual_P'], columns = ['Pred_U','Actual_A','Pred_P'])\n",
    "\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2edebcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of confusion matrices for our multilabel confusion matrix\n",
    "mcm_dict = {}\n",
    "for i in np.arange(0,3):\n",
    "    mcm_dict.update({f'Confusion Matrix {i+1}': pd.DataFrame(mcm[i], columns = ['Pred_Neg','Pred_Pos'], index = ['Acc_Neg','Acc_Pos'])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da8cd49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred_Neg</th>\n",
       "      <th>Pred_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Acc_Neg</th>\n",
       "      <td>781</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acc_Pos</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pred_Neg  Pred_Pos\n",
       "Acc_Neg       781        85\n",
       "Acc_Pos         7         1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcm_dict['Confusion Matrix 1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92b37eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcm_dict[f'Confusion Matrix 1']['Pred_Pos'].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0c6f832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Scoring for Unpopular songs\n",
      "         Pred_Neg  Pred_Pos\n",
      "Acc_Neg       781        85\n",
      "Acc_Pos         7         1\n",
      "The precision score is 0.011627906976744186\n",
      "The recall score is 0.125\n",
      "The accuracy score is 0.8947368421052632\n",
      "-------------------------------------\n",
      "Model Scoring for Average songs\n",
      "         Pred_Neg  Pred_Pos\n",
      "Acc_Neg       455       333\n",
      "Acc_Pos        37        49\n",
      "The precision score is 0.12827225130890052\n",
      "The recall score is 0.5697674418604651\n",
      "The accuracy score is 0.5766590389016019\n",
      "-------------------------------------\n",
      "Model Scoring for Popular songs\n",
      "         Pred_Neg  Pred_Pos\n",
      "Acc_Neg        68        26\n",
      "Acc_Pos       400       380\n",
      "The precision score is 0.9359605911330049\n",
      "The recall score is 0.48717948717948717\n",
      "The accuracy score is 0.5125858123569794\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "classes = ['Unpopular','Average','Popular']\n",
    "\n",
    "\n",
    "for i in np.arange(1,4):\n",
    "    print(f'Model Scoring for {classes[i-1]} songs')\n",
    "    TP = mcm_dict[f'Confusion Matrix {i}']['Pred_Pos'].values[1]                \n",
    "    TN = mcm_dict[f'Confusion Matrix {i}']['Pred_Neg'].values[0]\n",
    "    FP = mcm_dict[f'Confusion Matrix {i}']['Pred_Pos'].values[0]\n",
    "    FN = mcm_dict[f'Confusion Matrix {i}']['Pred_Neg'].values[1]\n",
    "    print(mcm_dict[f'Confusion Matrix {i}'])\n",
    "    precision = TP / (FP + TP)\n",
    "    recall = TP / (FN + TP)\n",
    "    accuracy = (TP + TN)/ (TP + FN + TN + FP)\n",
    "    \n",
    "    print(f'The precision score is {precision}')\n",
    "    print(f'The recall score is {recall}')\n",
    "    print(f'The accuracy score is {accuracy}')\n",
    "    print('-------------------------------------')\n",
    "          \n",
    "\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99b72680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4919908466819222"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show overall accuracy score\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7731b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['danceability', 'energy', 'loudness', 'mode', 'instrumentalness',\n",
       "       'valence', 'tempo', 'duration_ms'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe representing X_train so that the columns array can be used for creating a feature importances dataframe\n",
    "X_df = genre_df.drop(columns=['popularity_binned'])\n",
    "X_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "849c5a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Unpopular       0.01      0.12      0.02         8\n",
      "     Average       0.13      0.57      0.21        86\n",
      "     Popular       0.94      0.49      0.64       780\n",
      "\n",
      "    accuracy                           0.49       874\n",
      "   macro avg       0.36      0.39      0.29       874\n",
      "weighted avg       0.85      0.49      0.59       874\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "cr = classification_report(y_test, y_pred, target_names = classes)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37819719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check feature importance\n",
    "feat_imp = rfc.feature_importances_\n",
    "\n",
    "# We can sort the features by their importance.\n",
    "feat_imp = sorted(zip(rfc.feature_importances_, X_df.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8d68b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.201743</td>\n",
       "      <td>tempo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.167661</td>\n",
       "      <td>valence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.159640</td>\n",
       "      <td>instrumentalness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.136021</td>\n",
       "      <td>danceability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.117233</td>\n",
       "      <td>duration_ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.110934</td>\n",
       "      <td>loudness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.086335</td>\n",
       "      <td>energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.020433</td>\n",
       "      <td>mode</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Importance           Feature\n",
       "0    0.201743             tempo\n",
       "1    0.167661           valence\n",
       "2    0.159640  instrumentalness\n",
       "3    0.136021      danceability\n",
       "4    0.117233       duration_ms\n",
       "5    0.110934          loudness\n",
       "6    0.086335            energy\n",
       "7    0.020433              mode"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create feature importances dataframe\n",
    "feat_imp_df = pd.DataFrame(feat_imp, columns = ['Importance','Feature'])\n",
    "feat_imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314372a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
